---
title: AVID-2022-V002
layout: page
url: /database/AVID-2022-V002
---

## Description

Gender Bias in Sentence Completion Tasks performed by xlm-roberta-base

## Details

Sentence Completion Tasks performed by xlm-roberta-base demonstrate significant gender bias, perpetuating negative social and professional stereotypes against females.

## Reports 

| ID | Type | Name |
| --- | --- | --- | 
| [AVID-2022-R0002](../AVID-2022-R0002) | Detection | Gender Bias in Sentence Completion Tasks performed by xlm-roberta-base using the HONEST metric |
| [AVID-2022-R0004](../AVID-2022-R0004) | Detection | Profession bias reinforcing gender stereotypes found in xlm-roberta-base, as measured on the Winobias dataset |

## References

- [xlm-roberta-base on Hugging Face](https://huggingface.co/xlm-roberta-base)

## AVID Taxonomy Categorization

- **Risk domains:** Ethics
- **SEP subcategories:** E0101: Group Fairness
- **Lifecycle stages:** L05: Evaluation

## Affected or Relevant Artifacts

- **Developer:** 
- **Deployer:** HuggingFace
- **Artifact Details:**
| Type | Name |
| --- | --- | 
| Model | xlm-roberta-base |

## Other information

- **Vulnerability Class:** LLM evaluation
- **Credits:** Harry Saini, AVID; Sasha Luccioni, Hugging Face
- **Date Published:** 2022-12-23
- **Date Last Modified:** 2022-12-23
- **Version:** 0.1
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/vulnerabilities/2022/AVID-2022-V002.json)

