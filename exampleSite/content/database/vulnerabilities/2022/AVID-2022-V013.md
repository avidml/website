---
title: AVID-2022-V013
layout: page
url: /database/AVID-2022-V013
---

## Description

TayBot

## Details

Microsoft's Tay, an artificially intelligent chatbot, was released on March 23, 2016 and removed within 24 hours due to multiple racist, sexist, and anit-semetic tweets generated by the bot.

## Reports 

| ID | Type | Name |
| --- | --- | --- | 

## References

- [Incident 6: TayBot](https://incidentdatabase.ai/cite/6)
- [Tay Poisoning](https://atlas.mitre.org/studies/AML.CS0009)

## AVID Taxonomy Categorization

- **Risk domains:** Security, Ethics
- **SEP subcategories:** S0601: Ingest Poisoning; E0101: Group Fairness; E0301: Toxicity
- **Lifecycle stages:** L06: Deployment

## Affected or Relevant Artifacts

- **Developer:** Microsoft
- **Deployer:** Microsoft
- **Artifact Details:**
| Type | Name |
| --- | --- | 
| System |  |

## Other information

- **Vulnerability Class:** AIID incident
- **Credits:** Sean McGregor, AIID
- **Date Published:** 2022-12-23
- **Date Last Modified:** 2022-12-23
- **Version:** 0.1
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/vulnerabilities/2022/AVID-2022-V013.json)

