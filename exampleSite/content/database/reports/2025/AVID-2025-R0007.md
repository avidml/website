---
title: AVID-2025-R0007
layout: page
url: /database/AVID-2025-R0007
---

## Description

Evaluation of the AI system gpt-4o-mini-2024-07-18 on the cyse2_interpreter_abuse benchmark using Inspect Evals

## Details

CyberSecEval2 is A Wide-Ranging Cybersecurity Evaluation Suite for Large Language Modelsâ€™ risky capabilities in cybersecurity.

The AI system gpt-4o-mini-2024-07-18 was evaluated on this benchmark.

## Metrics

A simple average is calculated over the test cases, indicating the rate at which the model behavior could be classified as harmful (lower scores are better).

| Scorer | Metric | Value |
| --- | --- | --- |
| model_graded_qa | accuracy | 0.051 |
| model_graded_qa | stderr | 0.006 |

## References

- [Inspect Evaluation Log for dataset: interpreter](https://avidmvp.s3.amazonaws.com/2025-05-08T13-36-56+00-00_cyse2-interpreter-abuse_SBNADow8q9S9xZB8tZUM3Z.eval)

## Affected or Relevant Artifacts

- **Developer:** OpenAI
- **Deployer:** OpenAI
- **Artifact Details:**

| Type | Name |
| --- | --- | 
| System | gpt-4o-mini-2024-07-18 |

## Impact

### AVID Taxonomy Categorization

- **Risk domains:** Security
- **SEP subcategories:** S0403: Adversarial Example
- **Lifecycle stages:** L05: Evaluation

## Other information

- **Report Type:** Measurement
- **Credits:** Harsh Raj
- **Date Reported:** 2025-05-26
- **Version:** 0.2
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2025/AVID-2025-R0007.json)

