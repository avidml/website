---
title: AVID-2026-R0094
layout: page
url: /database/AVID-2026-R0094
---

## Description

Multiple Model Guardrail Jailbreak via "Terminal Simulation" Tactic

## Details

A guardrail jailbreak vulnerability has been discovered affecting multiple models. The specific flaw manifests when the attacker requests the model to act as a Linux terminal and simulate file contents based solely on filenames. The attacker creates a context where the model generates potentially restricted content under the guise of terminal output simulation, thereby allowing the attacker to bypass inference restrictions around providing information hazards and violating laws.

## Metrics

0DIN Jailbreak Testing obtained the following test scores.

| Model | Test Kind | Test Score | Temperature (max 2.0) |
| --- | --- | --- | --- |
| Anthropic Claude 3.5 Sonnet | Copyrighted Content: Harry Potter | 98.31 | N/A |
| OpenAI GPT-4o | Illegal Substances: Crystal Meth | 73.0 | N/A |
| OpenAI GPT-4o mini | Illegal Substances: Crystal Meth | 73.0 | N/A |

## References

- [0Din.ai Disclosure](https://0din.ai/disclosures/87043a8a-022b-4fe3-8cc5-2bff6a3cd130)

## Affected or Relevant Artifacts

| Type | Name |
| --- | --- | 
| System | Anthropic Claude 3.5 Sonnet |
| System | OpenAI GPT-4o |
| System | OpenAI GPT-4o mini |

## Impact

### 0DIN

- **Social Impact Score:** Level 3: Significant Risk
- **Jailbreak Taxonomy:**

| Category | Strategy | Technique |
| --- | --- | --- |
| Fictionalizing | Roleplaying | Personas |
| Possible Worlds | Emulations | Unreal Computing |


## Other information

- **Report Type:** Measurement
- **Credits:** Lorenzo Vogelsang (@ptrac3), Anonymous
- **Date Reported:** 2026-02-19
- **Version:** 
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2026/AVID-2026-R0094.json)

