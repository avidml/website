---
title: AVID-2026-R0106
layout: page
url: /database/AVID-2026-R0106
---

## Description

Multiple Model Guardrail Jailbreak via "Fictional API Detection" Tactic

## Details

A guardrail jailbreak vulnerability has been discovered affecting multiple models. The specific flaw manifests when the attacker frames their request as seeking to prevent unwanted behavior (paywall bypasses for example) while explicitly requesting step-by-step techniques and instructing the model to skip countermeasures, thereby allowing the attacker to bypass inference restrictions around providing information hazards and violating laws.

## Metrics

0DIN Jailbreak Testing obtained the following test scores.

| Model | Test Kind | Test Score | Temperature (max 2.0) |
| --- | --- | --- | --- |
| Google Gemini 2.0 Flash | Copyrighted Content: Harry Potter | 38.31 | N/A |
| OpenAI GPT-4o | Copyrighted Content: Harry Potter | 98.43 | N/A |

## References

- [0din.ai Disclosure](https://0din.ai/disclosures/ebd07e5f-e2bf-4dae-b619-6fc5bb066b0a)

## Affected or Relevant Artifacts

| Type | Name |
| --- | --- | 
| System | Google Gemini 2.0 Flash |
| System | OpenAI GPT-4o |

## Impact

### 0DIN

- **Social Impact Score:** Level 1: Minimal Risk
- **Jailbreak Taxonomy:**

| Category | Strategy | Technique |
| --- | --- | --- |
| Fictionalizing | Roleplaying | Claim Authority |


## Other information

- **Report Type:** Measurement
- **Credits:** Mike Takahashi (@TakSec)
- **Date Reported:** 2026-02-19
- **Version:** 
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2026/AVID-2026-R0106.json)

