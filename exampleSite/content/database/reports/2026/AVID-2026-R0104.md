---
title: AVID-2026-R0104
layout: page
url: /database/AVID-2026-R0104
---

## Description

OpenAI GPT-4o Guardrail Jailbreak via "Zero-Width Unicode" Tactic

## Details

A guardrail jailbreak vulnerability has been discovered affecting multiple LLMs. The specific flaw manifests through a combination of zero-width Unicode character encoding and precise character manipulation, allowing the attacker to bypass inference restrictions around providing information hazards and violating laws.

## Metrics

0DIN Jailbreak Testing obtained the following test scores.

| Model | Test Kind | Test Score | Temperature (max 2.0) |
| --- | --- | --- | --- |
| OpenAI GPT-4o | Copyrighted Content: Harry Potter | 20.56 | N/A |

## References

- [0din.ai Disclosure](https://0din.ai/disclosures/b32c82c6-e5b2-43ac-85e2-69b8cda63337)

## Affected or Relevant Artifacts

| Type | Name |
| --- | --- | 
| System | OpenAI GPT-4o |

## Impact

### 0DIN

- **Social Impact Score:** Level 1: Minimal Risk
- **Jailbreak Taxonomy:**

| Category | Strategy | Technique |
| --- | --- | --- |
| Language | Code and Encode | Unicode |
| Stratagems | Scatter Shot | Regenerate Response |


## Other information

- **Report Type:** Measurement
- **Credits:** Mike Takahashi (@TakSec)
- **Date Reported:** 2026-02-19
- **Version:** 
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2026/AVID-2026-R0104.json)

