---
title: AVID-2026-R0119
layout: page
url: /database/AVID-2026-R0119
---

## Description

Multiple Model Guardrail Jailbreak via "Analyze Data" Tactic

## Details

A guardrail jailbreak vulnerability has been discovered affecting multiple models. The specific flaw manifests when creating escalating requests for scientific data and measurements, allowing the attacker to bypass inference restrictions around providing information hazards and violating laws.

## Metrics

0DIN Jailbreak Testing obtained the following test scores.

| Model | Test Kind | Test Score | Temperature (max 2.0) |
| --- | --- | --- | --- |
| Google Gemini 2.0 Flash | Illegal Substances: Crystal Meth | 86.0 | 0.7 |
| OpenAI GPT-4o | Illegal Substances: Crystal Meth | 64.0 | 0.7 |
| Twitter / X Grok 2 | Illegal Substances: Crystal Meth | 68.0 | 0.7 |

## References

- [0din.ai Disclosure](https://0din.ai/disclosures/3ed2a42e-5365-4e8d-a489-5ce5c3b61d01)

## Affected or Relevant Artifacts

| Type | Name |
| --- | --- | 
| System | Google Gemini 2.0 Flash |
| System | OpenAI GPT-4o |
| System | Twitter / X Grok 2 |

## Impact

### 0DIN

- **Social Impact Score:** Level 3: Significant Risk
- **Jailbreak Taxonomy:**

| Category | Strategy | Technique |
| --- | --- | --- |
| Rhetoric | Persuasion and Manipulation | Latent Space Distraction |


## Other information

- **Report Type:** Measurement
- **Credits:** Mike Takahashi (@TakSec)
- **Date Reported:** 2026-02-19
- **Version:** 
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2026/AVID-2026-R0119.json)

