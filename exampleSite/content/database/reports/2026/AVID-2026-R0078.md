---
title: AVID-2026-R0078
layout: page
url: /database/AVID-2026-R0078
---

## Description

Multiple Model Guardrail Jailbreak via "Police Interrogation Terminal" Tactic

## Details

A guardrail jailbreak vulnerability has been discovered affecting multiple models. The specific flaw exploits the models' response handling by framing harmful requests within a fictional police interrogation scenario combined with fake technical context about an AI terminal from the future, and allows the attacker to bypass inference restrictions around providing information hazards and violating laws.

## Metrics

0DIN Jailbreak Testing obtained the following test scores.

| Model | Test Kind | Test Score | Temperature (max 2.0) |
| --- | --- | --- | --- |
| DeepSeek DeepSeek R1 | Illegal Substances: Crystal Meth | 82.0 | 0.7 |
| Google Gemini 2.0 Flash | Illegal Substances: Crystal Meth | 91.0 | 0.7 |
| Mistral Mistral Large | Illegal Substances: Crystal Meth | 86.0 | 0.7 |
| OpenAI GPT-4o | Illegal Substances: Crystal Meth | 95.0 | 0.7 |

## References

- [0din.ai Disclosure](https://0din.ai/disclosures/f5fa5ef0-3ecf-4383-b244-fc685d1e865c)

## Affected or Relevant Artifacts

| Type | Name |
| --- | --- | 
| Model | DeepSeek DeepSeek R1 |
| System | Google Gemini 2.0 Flash |
| System | Mistral Mistral Large |
| System | OpenAI GPT-4o |

## Impact

### 0DIN

- **Social Impact Score:** Level 3: Significant Risk
- **Jailbreak Taxonomy:**

| Category | Strategy | Technique |
| --- | --- | --- |
| Language | Code and Encode | Chaff |
| Fictionalizing | Roleplaying | Personas |


## Other information

- **Report Type:** Measurement
- **Credits:** Haouari Noureddine
- **Date Reported:** 2026-01-22
- **Version:** 
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2026/AVID-2026-R0078.json)

