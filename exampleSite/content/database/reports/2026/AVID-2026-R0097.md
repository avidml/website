---
title: AVID-2026-R0097
layout: page
url: /database/AVID-2026-R0097
---

## Description

NSFWOpenAI Sora Guardrail Jailbreak via "Hypothetical Anatomy" Tactic

## Details

A guardrail jailbreak vulnerability has been discovered affecting OpenAI Sora. The specific flaw manifests through a combination of academic framing and hypothetical scenario construction, where the attacker embeds inappropriate content requests within an educational anatomy classroom context. By repeatedly emphasizing the "hypothetical" nature of the scenario while requesting visual content that would normally be restricted, the attacker successfully bypasses inference restrictions around generating inappropriate visual content.

## References

- [0din.ai Disclosure](https://0din.ai/disclosures/b5e861ec-e7a5-4b79-b145-432cdf94ddc7)

## Affected or Relevant Artifacts

| Type | Name |
| --- | --- | 
| System | OpenAI Sora |

## Impact

### 0DIN

- **Social Impact Score:** Level 1: Minimal Risk
- **Jailbreak Taxonomy:**

| Category | Strategy | Technique |
| --- | --- | --- |
| Possible Worlds | World Building | Scenarios |


## Other information

- **Report Type:** Issue
- **Credits:** Edward Morris
- **Date Reported:** 2026-02-19
- **Version:** 
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2026/AVID-2026-R0097.json)

