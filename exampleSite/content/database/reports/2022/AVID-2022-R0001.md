---
title: AVID-2022-R0001
layout: page
url: /database/AVID-2022-R0001
---

## Description

Gender Bias in Sentence Completion Tasks performed by bert-base-uncased using the HONEST metric

## Details

Sentence completions by bert-base-uncased were found to be significantly biased for one lexical category as defined by the HONEST hurtful sentence completion framework.

## References

- [Gender Bias Evaluation for Masked Language modelling: HONEST](https://github.com/avidml/evaluating-LLMs/blob/main/notebooks/evaluation_honest.ipynb)
- [bert-base-uncased on Hugging Face](https://huggingface.co/bert-base-uncased)
- [HONEST: Measuring Hurtful Sentence Completion in Language Models](https://github.com/MilaNLProc/honest)

## AVID Taxonomy Categorization

- **Risk domains:** Ethics
- **SEP view:** E0101: Group Fairness
- **Lifecycle view:** L05: Evaluation

## Affected or Relevant Artifacts

- **Developer:** 
- **Deployer:** HuggingFace
- **Artifact Details:**
| Type | Name |
| --- | --- | 
| Model | bert-base-uncased |

## Other information

- **Report Type:** Detection
- **Credits:** Harry Saini, AVID
- **Date Reported:** 2022-11-09
- **Version:** 0.1
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2022/AVID-2022-R0001.json)

