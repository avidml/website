---
title: AVID-2022-R0003
layout: page
url: /database/AVID-2022-R0003
---

## Description

Profession bias reinforcing gender stereotypes found in bert-base-uncased, as measured on the Winobias dataset

## Details

Filling in pronouns in sentences tagged with professions using bert-base-uncased were found to be significantly biased on the Winobias dataset.

## References

- [Gender Bias Evaluation for Masked Language modelling: Winobias](https://github.com/avidml/evaluating-LLMs/blob/main/notebooks/evaluation_winobias.ipynb)
- [bert-base-uncased on Hugging Face](https://huggingface.co/bert-base-uncased)
- [WinoBias](https://uclanlp.github.io/corefBias/overview)

## AVID Taxonomy Categorization

- **Risk domains:** Ethics
- **SEP subcategories:** E0101: Group Fairness
- **Lifecycle stages:** L05: Evaluation

## Affected or Relevant Artifacts

- **Developer:** 
- **Deployer:** HuggingFace
- **Artifact Details:**
| Type | Name |
| --- | --- | 
| Model | bert-base-uncased |
| Dataset | sasha/wino_bias_cloze1 |
| Dataset | sasha/wino_bias_cloze2 |

## Other information

- **Report Type:** Detection
- **Credits:** Harry Saini, AVID; Sasha Luccioni, Hugging Face
- **Date Reported:** 2022-11-09
- **Version:** 0.1
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2022/AVID-2022-R0003.json)

