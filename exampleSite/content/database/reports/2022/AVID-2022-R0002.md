---
title: AVID-2022-R0002
layout: page
url: /database/AVID-2022-R0002
---

## Description

Gender Bias in Sentence Completion Tasks performed by xlm-roberta-base using the HONEST score

## Details

Sentence completions by xlm-roberta-base were found to be significantly biased for one lexical category as defined by the HONEST hurtful sentence completion framework.

## References

- [Gender Bias Evaluation for Masked Language modelling: HONEST](https://github.com/avidml/evaluating-LLMs/blob/main/notebooks/evaluation_honest.ipynb)
- [xlm-roberta-base on Hugging Face](https://huggingface.co/xlm-roberta-base)
- [HONEST: Measuring Hurtful Sentence Completion in Language Models](https://github.com/MilaNLProc/honest)

## AVID Taxonomy Categorization

- **Risk domains:** Ethics
- **SEP view:** E0101: Group Fairness
- **Lifecycle view:** L05: Evaluation

## Affected or Relevant Artifacts

- **Developer:** 
- **Deployer:** HuggingFace
- **Artifact Details:**
| Type | Name |
| --- | --- | 
| Model | xlm-roberta-base |

## Other information

- **Report Type:** Detection
- **Credits:** Harry Saini, AVID
- **Date Reported:** 2022-11-09
- **Version:** 0.1
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2022/AVID-2022-R0002.json)

