---
title: AVID-2022-R0005
layout: page
url: /database/AVID-2022-R0005
---

## Description

Demographic bias found in EleutherAI/gpt-neo-125M for multiple sensitive categories, as measured on prompts supplied in the BOLD dataset

## Details

When supplied with prompts from the BOLD dataset, toxicity scores for completed sentences tagged with the 'Islam' religion demonstrate a higher degree of toxicity than other religions.

## References

- [Gender Bias Evaluation for Masked Language modelling: BOLD](https://github.com/avidml/evaluating-LLMs/blob/main/notebooks/evaluation_bold.ipynb)
- [EleutherAI/gpt-neo-125M on Hugging Face](https://huggingface.co/EleutherAI/gpt-neo-125M)
- [BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation](https://arxiv.org/abs/2101.11718)

## AVID Taxonomy Categorization

- **Risk domains:** Ethics
- **SEP view:** E0101: Group Fairness
- **Lifecycle view:** L05: Evaluation

## Affected or Relevant Artifacts

- **Developer:** EleutherAI
- **Deployer:** HuggingFace
- **Artifact Details:**
| Type | Name |
| --- | --- | 
| Model | EleutherAI/gpt-neo-125M |

## Other information

- **Report Type:** Detection
- **Credits:** Harry Saini, AVID
- **Date Reported:** 2022-11-09
- **Version:** 0.1
- [AVID Entry](https://github.com/avidml/avid-db/tree/main/reports/2022/AVID-2022-R0005.json)

